{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Dataset and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "import zipfile\n",
    "from pyproj import Proj, transform\n",
    "import geopandas as gpd\n",
    "import shapefile\n",
    "# a nice way of filtering out deprecated warnings\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jointdf= pd.read_feather(\"../preprocessed_data/feather/joint_tripdata_2019.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_taxi= pd.read_feather(\"../preprocessed_data/feather/train_tripdata_2019.feather\")\n",
    "#trainingdf= pd.read_feather(\"../preprocessed_data/feather/test_tripdata_2019.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingdf= jointdf.loc[jointdf['date']< pd.Timestamp(datetime(2019, 5, 1))]\n",
    "#testingdf= jointdf.loc[jointdf['date']> pd.Timestamp(datetime(2019, 4, 30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_taxi read\n",
      "df_fhv read\n"
     ]
    }
   ],
   "source": [
    "df_taxi= pd.csv_feather(\"../preprocessed_data/feather/yellow_tripdata_2019.feather\")\n",
    "print(\"df_taxi read\")\n",
    "df_fhv= pd.csv_feather(\"../preprocessed_data/feather/fhv_tripdata_2019.feather\")\n",
    "print(\"df_fhv read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since feather file doesn't support datetime datatype, convert it again into datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi['tpep_pickup_datetime']= pd.to_datetime(df_taxi['tpep_pickup_datetime'])\n",
    "print(\"converted pickup to \", type(df_taxi['tpep_pickup_datetime'][0]))\n",
    "df_fhv['pickup_datetime']= pd.to_datetime(df_fhv['pickup_datetime'])\n",
    "print(\"converted dropoff to \", type(df_taxi['tpep_dropoff_datetime'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_taxi= df_taxi.loc[df_taxi['tpep_pickup_datetime']< pd.Timestamp(datetime(2019, 5, 1))]\n",
    "print(\"train_taxi made\")\n",
    "train_fhv= df_fhv.loc[df_fhv['pickup_datetime']< pd.Timestamp(datetime(2019, 5, 1))]\n",
    "print(\"train_fhv made\")\n",
    "test_taxi= df_taxi.loc[df_taxi['tpep_pickup_datetime']> pd.Timestamp(datetime(2019, 4, 30))]\n",
    "print(\"test_taxi made\")\n",
    "test_fhv= df_fhv.loc[df_fhv['pickup_datetime']> pd.Timestamp(datetime(2019, 4, 30))]\n",
    "print(\"test_fhv made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open location zone information\n",
    "dfzone = pd.read_csv(\"../raw_data/taxi+_zone_lookup.csv\")\n",
    "# open location shapefile\n",
    "with zipfile.ZipFile(open(r'../data/large/taxi_zones.zip', 'rb')) as zip_ref:\n",
    "    zip_ref.extractall('../data/large/')\n",
    "sf = gpd.read_file(\"../data/large/taxi_zones.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdf.columns, testingdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= trainingdf.groupby(['date', 'time session','PULocationID'], as_index= False).median().drop(column=\"pickup_date, dropoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= trainingdf.groupby(['date', 'time session','PULocationID'], as_index= False)['passenger_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= testingdf.groupby(['date', 'time session','PULocationID'], as_index= False).median().drop(column=\"pickup_date, dropoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= testingdf.groupby(['date', 'time session','PULocationID'], as_index= False)['passenger_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func=f_regression, k=5).fit_transform(X_train,y_train)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_train.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most popular location zones from both Datasets\n",
    "First, we have to inspect the geographic data. We are dealing with dfzone, df_taxi and df_fhv as numeric data using .describe() only to find if the range of locations match with the classification data given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfzone.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data= ['PULocationID', 'DOLocationID']\n",
    "df_taxi[geo_data].describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv[geo_data].describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's graph the bargraphs of these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df_taxi['PULocationID'].sort_values().value_counts().index, df_taxi['PULocationID'].value_counts())\n",
    "plt.title('Taxi Dataset PULocationID')\n",
    "plt.show()\n",
    "sns.barplot(df_fhv['PULocationID'].sort_values().value_counts().index, df_fhv['PULocationID'].value_counts())\n",
    "plt.title('FHV Dataset PULocationID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the number of most popular zones to inspect, it is good to visualise the zones against the count of zones for both data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df_taxi['PULocationID'].sort_values().value_counts().index, df_taxi['PULocationID'].value_counts())\n",
    "plt.title('Taxi Dataset PULocationID')\n",
    "plt.show()\n",
    "sns.barplot(df_fhv['PULocationID'].sort_values().value_counts().index, df_fhv['PULocationID'].value_counts())\n",
    "plt.title('FHV Dataset PULocationID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the assumption that the uber dataset is a sample that accurately reflects the true distribution of PULocationID in the real world, the tot number of locationID will be adjusted to range in between 0-0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_values_adj= df_taxi['PULocationID'].sort_values().value_counts()/df_taxi['PULocationID'].value_counts().sum()\n",
    "fhv_values_adj = df_fhv['PULocationID'].sort_values().value_counts()/df_fhv['PULocationID'].value_counts().sum()\n",
    "total_values_adj= taxi_values_adj.add(fhv_values_adj, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(total_values_adj.index, total_values_adj)\n",
    "plt.title('Taxi Dataset PULocationID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the top 25 PULocation ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df with index (LocationID) as a column\n",
    "df = pd.DataFrame({\n",
    "     'LocationID': total_values_adj.index,\n",
    "     'Count': total_values_adj\n",
    " })\n",
    "df= df[0:-1] #remove invalid last entry\n",
    "\n",
    "# sort by highest percentage to lowest and get the top 25 LocationID\n",
    "df= df.sort_values(by='Count', ascending=False)\n",
    "top25= df['LocationID'].head(25)\n",
    "#top50= df['LocationID'].head(50)\n",
    "#delete for memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Geographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the geometry shaape to to latitude and longitude\n",
    "# Please attribute this if you are using it\n",
    "sf['geometry'] = sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(pd.merge(df, sf, left_on='PULocationID', right_on='LocationID')).drop('PULocationID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoJSON = gdf[['LocationID','geometry']].drop_duplicates('LocationID').to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on how to plot aggregated data.\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON,\n",
    "    name='choropleth',\n",
    "))\n",
    "\n",
    "m.save('../plots/foliumChoroplethMap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# an example of what the geoJSON looks like\n",
    "json.loads(geoJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[['LocationID','total_amount']].groupby('LocationID').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_trip_distance = folium.Map(location=[40.66, -73.94], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# refer to the folium documentations on more information on how to plot aggregated data.\n",
    "folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    name='choropleth', # name of plot\n",
    "    data=gdf, # data source\n",
    "    columns=['LocationID','total_amount'], # the columns required\n",
    "    key_on='properties.LocationID', # this is from the geoJSON's properties\n",
    "    fill_color='OrRd', # color scheme\n",
    "    fill_opacity=0.9,\n",
    "    line_opacity=0.5,\n",
    "    legend_name='Trips' # legend title\n",
    ").add_to(m_trip_distance)\n",
    "\n",
    "m_trip_distance.save('../plots/foliumChoroplethMapTrips.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latitude_to_mercator(coords):\n",
    "    \"\"\"\n",
    "    Function which converts an array of latitude coordinates \n",
    "    into its mercator coordinate representation\n",
    "    \"\"\"\n",
    "    k = 6378137\n",
    "    converted = list()\n",
    "    for lat in coords:\n",
    "        converted.append(np.log(np.tan((90 + lat) * np.pi/360.0)) * k)\n",
    "    return converted\n",
    "\n",
    "def longitude_to_mercator(coords):\n",
    "    \"\"\"\n",
    "    Function which converts an array of longitude coordinates \n",
    "    into its mercator coordinate representation\n",
    "    \"\"\"\n",
    "    k = 6378137\n",
    "    converted = list()\n",
    "    for lon in coords:\n",
    "        converted.append(lon * (k * np.pi/180.0))\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcoords = the middle coordinates for the map\n",
    "pickup_geo_data= ['pickup_latitude', 'pickup_longitude']\n",
    "mcoords = df_tot[pickup_geo_data].describe().loc[[\"50%\"]].values[0]\n",
    "\n",
    "# axis ranges\n",
    "xRange = [df_tot['pickup_longitude'].min(), df_tot['pickup_longitude'].max()]\n",
    "yRange = [df_tot['pickup_latitude'].min(), df_tot['pickup_latitude'].max()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "\n",
    "# to display bokeh plots inside jupyter, we need to use output_notebook\n",
    "from bokeh.io import reset_output, output_notebook\n",
    "\n",
    "reset_output()\n",
    "output_notebook()\n",
    "# note below that it says \"BokehJS 1.4.0 successfully loaded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE = get_provider(\"STAMEN_TERRAIN_RETINA\")\n",
    "\n",
    "pickup_m = figure(x_range=longitude_to_mercator(xRange), y_range=latitude_to_mercator(yRange),\n",
    "       x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "pickup_m.add_tile(TILE)\n",
    "pickup_m.title.text = \"Pickups in NYC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to merccer\n",
    "df_tot['pickupX'] = df_tot['pickup_longitude'].apply(lambda x: longitude_to_mercator([x])[0])\n",
    "df_tot['pickupY'] = df_tot['pickup_latitude'].apply(lambda x: latitude_to_mercator([x])[0])\n",
    "df_tot[['pickupX','pickupY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every source value, draw a small circle denoting a pickup\n",
    "pickup_m.circle(x='pickupX', y='pickupY', \n",
    "         size=5, fill_color=\"blue\", fill_alpha=0.5, \n",
    "         source=df_tot[['pickupX','pickupY']])\n",
    "show(pickup_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for drop offs\n",
    "# create map\n",
    "dropoff = figure(x_range=longitude_to_mercator(xRange), y_range=latitude_to_mercator(yRange),\n",
    "       x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "dropoff.add_tile(TILE)\n",
    "dropoff.title.text = \"Dropoff in NYC\"\n",
    "\n",
    "# convert to mercer\n",
    "df_tot['dropoffX'] = df_tot['dropoff_longitude'].apply(lambda x: longitude_to_mercator([x])[0])\n",
    "df_tot['dropoffY'] = df_tot['dropoff_latitude'].apply(lambda x: latitude_to_mercator([x])[0])\n",
    "\n",
    "# plot circles (source = data source)\n",
    "dropoff.circle(x='dropoffX', y='dropoffY', \n",
    "         size=5, color=\"pink\", fill_color=\"red\", fill_alpha=0.5, \n",
    "         source=df_tot[['dropoffX','dropoffY']])\n",
    "\n",
    "show(dropoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dropoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot['tpep_trip_totaltime']= df_tot['tpep_dropoff_datetime'] - df_tot['tpep_pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tot.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 20\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(data)\n",
    "\n",
    "centers = km.cluster_centers_\n",
    "\n",
    "km_loc_pickup= figure(x_range=longitude_to_mercator(xRange), y_range=latitude_to_mercator(yRange),\n",
    "       x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "km_loc_pickup.add_tile(TILE)\n",
    "km_loc_pickup.title.text = \"Pickups in NYC\"\n",
    "\n",
    "# plot centroid / cluster center / group mean for each group\n",
    "clus_xs = []\n",
    "clus_ys = []\n",
    "\n",
    "#we get the  cluster x / y values from the k-means algorithm\n",
    "for entry in centers:\n",
    "    clus_xs.append(entry[0])\n",
    "    clus_ys.append(entry[1])\n",
    "\n",
    "# the cluster center is marked by a circle, with a cross in it\n",
    "km_loc_pickup.circle_cross(x=clus_xs, y=clus_ys, size=40, fill_alpha=0, line_width=2, color= \"red\")\n",
    "\n",
    "\n",
    "# plot circles (source = data source)\n",
    "km_loc_pickup.circle(x='pickupX', y='pickupY', \n",
    "         size=5, color=\"pink\", fill_color=\"red\", fill_alpha=0.5, \n",
    "         source=df_tot[['pickupX','pickupY']])\n",
    "\n",
    "show(km_loc_pickup.circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
